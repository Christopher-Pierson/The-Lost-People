{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "1. ~Fix counties for unclaimed~\n",
    "2. ~Fix counties for unidentified~\n",
    "3. ~Add line to state_centroids with south pole coordinates and nonsense FIPS code~\n",
    "4. ~Re-export state-level json (now that county fields have been updated within the databases and American Samoa has been removed)~\n",
    "    * ~MAKE SURE TO MAP NAS to nonsense FIPS~\n",
    "5. ~Add to county centroids:~\n",
    "    * ~55 lines with south pole coordinates and nonsense county FIPS codes (state only_999)~\n",
    "    * ~1 line with south pole coordinates and nonsense FIPS code (99)~\n",
    "6. ~Format county data - state name, and then name and county FIPS code, to get GEOID~\n",
    "7. ~Export county-level json~\n",
    "    * ~any records with no county get pulled (to separate state FIPS with no county key and nonsense coordinates [south pole])~\n",
    "    * ~make sure state name included as field with each database, not just FIPS code~\n",
    "8. ~Re-export summary count JSON (as a few cases have been deleted)~\n",
    "    * ~Address 21 NAs for Unclaimed?~\n",
    "9. ~Clean null values for age and gender and sex and race / ethnicity~\n",
    "10. ~Re-export state and county JSONS~\n",
    "11. Make GeoJSON of state polygons\n",
    "12. Make GeoJSON of county polygons\n",
    "13. Make summary GeoJSON with county counts\n",
    "14. See how bad city data would be\n",
    "    * likely need to make all city names .lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. Edits to Missing_04182020.csv prior to import\n",
    "  * Virgin Islands (to United States Virgin Islands), \n",
    "  * Tennesse (to Tennessee), and \n",
    "  * Northern Mariana Islands (to Commonwealth of the Northern Mariana Islands)\n",
    "  * Address all county nulls\n",
    "2. Edits to Unclaimed_0418202.csv priort to import\n",
    "  * Address all county nulls\n",
    "3. Edits to Unidentified_04182020.csv prior to import\n",
    "  * Virgin Islands (to United States Virgin Islands)\n",
    "  * Address all county nulls\n",
    "4. Edits to state_centroids_v2 prior to import\n",
    "  * Add one row with south pole coordinates and nonsense FIPS code(99) - for cases w/ no city, county, or state\n",
    "5. Edits to county_centroids_v2 prior to import\n",
    "  * Add one row with south pole coordinates and nonsense FIPS code(99) - for cases w/ no city, county, or state\n",
    "  * Add 55 rows with south pole coordinates and nonsense county FIPS codes(999) - for cases w/ no city or county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csvs\n",
    "city_df = pd.read_csv('cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_centroids_df = pd.read_csv('state_centroids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate centroids - with None option with FIPS 99\n",
    "state_centroids_v2_df = pd.read_csv('state_centroids_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_centroids_df = pd.read_csv('county_centroids.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate centroids - with None options with count FIPS 999\n",
    "county_centroids_v2_df = pd.read_csv('county_centroids_v2.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.read_csv('Missing_04182020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df = pd.read_csv('Unclaimed_04182020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidentified_df = pd.read_csv('Unidentified_04182020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "county_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Summary data (count for all 3 databases, by state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/4: Get count of missing person cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = missing_df.groupby('State').count()\n",
    "len(missing_count)\n",
    "missing_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns except case number count\n",
    "missing_count = missing_count.drop(columns=['DLC','Last Name', 'First Name', 'Missing Age', 'City', 'County', 'Sex', 'Race / Ethnicity', 'Date Modified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for state (since state is now index)\n",
    "missing_count['State'] = missing_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename case number count column\n",
    "missing_count = missing_count.rename(columns = {'Case Number': 'Missing_CaseCount'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "missing_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of states and missing person counts\n",
    "missing_dict = dict(zip(missing_count.State, missing_count.Missing_CaseCount))\n",
    "len(missing_dict)\n",
    "# missing_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of values in missing database w/ no state assigned\n",
    "mis_null_series = missing_df.loc[missing_df['State'].isnull()].count()\n",
    "mis_null_ct = mis_null_series['Case Number']\n",
    "mis_null_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2/4: Get count of unclaimed persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_count = unclaimed_df.groupby('State').count()\n",
    "# len(unclaimed_count)\n",
    "unclaimed_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns except case number count\n",
    "unclaimed_count = unclaimed_count.drop(columns=['DBF','Last Name', 'First Name', 'Sex', 'Race / Ethnicity', 'City', 'County', 'Date Modified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for state (since state is now index)\n",
    "unclaimed_count['State'] = unclaimed_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename case number count column\n",
    "unclaimed_count = unclaimed_count.rename(columns = {'Case Number': 'Unclaimed_CaseCount'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "unclaimed_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of states and unclaimed case counts\n",
    "unclaimed_dict = dict(zip(unclaimed_count.State, unclaimed_count.Unclaimed_CaseCount))\n",
    "len(unclaimed_dict)\n",
    "# unclaimed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of values in unclaimed database w/ no state assigned\n",
    "unc_null_series = unclaimed_df.loc[unclaimed_df['State'].isnull()].count()\n",
    "unc_null_ct = unc_null_series['Case Number']\n",
    "unc_null_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3/4: Get count of unidentified persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidentified_count = unidentified_df.groupby('State').count()\n",
    "# len(unidentified_count)\n",
    "unidentified_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns except case number count\n",
    "unidentified_count = unidentified_count.drop(columns=['DBF','Age From', 'Age To', 'City', 'County', 'Sex', 'Race / Ethnicity', 'Date Modified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for state (since state is now index)\n",
    "unidentified_count['State'] = unidentified_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename case number count column\n",
    "unidentified_count = unidentified_count.rename(columns = {'Case Number': 'Unidentified_CaseCount'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "unidentified_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of states and unidentified case counts\n",
    "unidentified_dict = dict(zip(unidentified_count.State, unidentified_count.Unidentified_CaseCount))\n",
    "len(unidentified_dict)\n",
    "# unidentified_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of values in unidentified database w/ no state assigned\n",
    "uni_null_series = unidentified_df.loc[unidentified_df['State'].isnull()].count()\n",
    "uni_null_ct = uni_null_series['Case Number']\n",
    "uni_null_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/4: Make summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new summary dataframe based on the state centroids\n",
    "summary_df = state_centroids_v2_df\n",
    "# sort by state name\n",
    "summary_df = summary_df.sort_values(by=['STATEFP'])\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a: Add Missing Person count for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the missing_dict, to pull the correct missing case count for each state\n",
    "summary_df['Missing_Count'] = summary_df['NAME'].map(missing_dict)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b: Add Unclaimed Person count for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the unclaimed_dict, to pull the correct unclaimed case count for each state\n",
    "summary_df['Unclaimed_Count'] = summary_df['NAME'].map(unclaimed_dict)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values [NOTE: seems fine to have nulls]\n",
    "unclaimed_null_df = summary_df.loc[summary_df['Unclaimed_Count'].isnull()]\n",
    "unclaimed_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN Unclaimed count for fake FIPS 99 to count of values in missing database w/ no state assigned (21)\n",
    "index_Series = summary_df.loc[summary_df['STATEFP']==99]\n",
    "index_None = index_Series.index[0]\n",
    "summary_df.loc[index_None, 'Unclaimed_Count'] = unc_null_ct\n",
    "# check value\n",
    "summary_df['Unclaimed_Count'][index_None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b: Add Unidentified Person count for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the unidentified_dict, to pull the correct unidentified case count for each state\n",
    "summary_df['Unidentified_Count'] = summary_df['NAME'].map(unidentified_dict)\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values [NOTE: seems fine to have nulls]\n",
    "unidentified_null_df = summary_df.loc[summary_df['Unidentified_Count'].isnull()]\n",
    "unidentified_null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c: Add column for total count of cases in all three databases for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.iloc[:, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - may need to change -4 to -3, run, then change back to -4 and re-run. DON'T KNOW WHY\n",
    "summary_df['Total_Count'] = summary_df.iloc[:, -4:-1].sum(axis=1)\n",
    "summary_df.head(56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c: Convert to geodataframe and export as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check final summary_df\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to geodataframe\n",
    "summary_gdf = gpd.GeoDataFrame(summary_df, geometry=gpd.points_from_xy(x=summary_df.Lon_dd, y=summary_df.Lat_dd))\n",
    "summary_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to geoJSON\n",
    "summary_gdf.to_file(\"JSON/summary_counts.json\", driver=\"GeoJSON\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Prep data by replacing null attribute values [NOT CITY, COUNTY, OR STATE - Those are addressed later]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Missing dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for null values, and replace as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for DLC [NOTE: Leave as NaN]\n",
    "missing_attr_df = missing_df.loc[missing_df['DLC'].isnull()]\n",
    "# len(missing_attr_df)\n",
    "missing_attr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for Missing Age\n",
    "missing_attr_1_df = missing_df.loc[missing_df['Missing Age'].isnull()]\n",
    "# len(missing_attr_1_df)\n",
    "missing_attr_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing age values to be 'Unknown'\n",
    "missing_df['Missing Age'] = missing_df['Missing Age'].fillna('Unknown')\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "missing_age_test_df = missing_df.loc[missing_df['Missing Age']=='Unknown']\n",
    "missing_age_test_df\n",
    "# len(missing_age_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for Race / Ethnicity\n",
    "missing_attr_2_df = missing_df.loc[missing_df['Race / Ethnicity'].isnull()]\n",
    "# len(missing_attr_2_df)\n",
    "missing_attr_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing race / ethnicity values to be 'Uncertain'\n",
    "missing_df['Race / Ethnicity'] = missing_df['Race / Ethnicity'].fillna('Uncertain')\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "missing_race_test_df = missing_df.loc[missing_df['Race / Ethnicity']=='Uncertain']\n",
    "missing_race_test_df\n",
    "# len(missing_race_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force all names to lowercase then capitalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['Last Name'] = missing_df['Last Name'].str.lower()\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['Last Name'] = missing_df['Last Name'].str.capitalize()\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['First Name'] = missing_df['First Name'].str.lower()\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['First Name'] = missing_df['First Name'].str.capitalize()\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Unclaimed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for null values, and replace as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for DBF [NOTE: Leave as NaN]\n",
    "unclaimed_attr_df = unclaimed_df.loc[unclaimed_df['DBF'].isnull()]\n",
    "# len(unclaimed_attr_df)\n",
    "unclaimed_attr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for last name\n",
    "unclaimed_attr_1_df = unclaimed_df.loc[unclaimed_df['Last Name'].isnull()]\n",
    "# len(unclaimed_attr_1_df)\n",
    "unclaimed_attr_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing last name values to be 'Unknown'\n",
    "unclaimed_df['Last Name'] = unclaimed_df['Last Name'].fillna('Unknown')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unclaimed_lname_test_df = unclaimed_df.loc[unclaimed_df['Last Name']=='Unknown']\n",
    "unclaimed_lname_test_df\n",
    "# len(unclaimed_lname_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for first name\n",
    "unclaimed_attr_2_df = unclaimed_df.loc[unclaimed_df['First Name'].isnull()]\n",
    "# len(unclaimed_attr_2_df)\n",
    "unclaimed_attr_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing first name values to be 'Unknown'\n",
    "unclaimed_df['First Name'] = unclaimed_df['First Name'].fillna('Unknown')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unclaimed_fname_test_df = unclaimed_df.loc[unclaimed_df['First Name']=='Unknown']\n",
    "unclaimed_fname_test_df\n",
    "# len(unclaimed_fname_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for sex\n",
    "unclaimed_attr_3_df = unclaimed_df.loc[unclaimed_df['Sex'].isnull()]\n",
    "# len(unclaimed_attr_3_df)\n",
    "unclaimed_attr_3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing sex values to be 'Unknown'\n",
    "unclaimed_df['Sex'] = unclaimed_df['Sex'].fillna('Unknown')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unclaimed_sex_test_df = unclaimed_df.loc[unclaimed_df['Sex']=='Unknown']\n",
    "unclaimed_sex_test_df\n",
    "# len(unclaimed_sex_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for race / ethnicity\n",
    "unclaimed_attr_4_df = unclaimed_df.loc[unclaimed_df['Race / Ethnicity'].isnull()]\n",
    "# len(unclaimed_attr_4_df)\n",
    "unclaimed_attr_4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing race / ethnicity values to be 'Uncertain'\n",
    "unclaimed_df['Race / Ethnicity'] = unclaimed_df['Race / Ethnicity'].fillna('Uncertain')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unclaimed_race_test_df = unclaimed_df.loc[unclaimed_df['Race / Ethnicity']=='Uncertain']\n",
    "unclaimed_race_test_df\n",
    "# len(unclaimed_race_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force all names to lowercase, then capitalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df['Last Name'] = unclaimed_df['Last Name'].str.lower()\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df['Last Name'] = unclaimed_df['Last Name'].str.capitalize()\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df['First Name'] = unclaimed_df['First Name'].str.lower()\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df['First Name'] = unclaimed_df['First Name'].str.capitalize()\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Unidentified dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for null values, and replace as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for DBF [NOTE: Leave as NaN]\n",
    "unidentified_attr_df = unidentified_df.loc[unidentified_df['DBF'].isnull()]\n",
    "# len(unidentified_attr_df)\n",
    "unidentified_attr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for Age From\n",
    "unidentified_attr_1_df = unidentified_df.loc[unidentified_df['Age From'].isnull()]\n",
    "# len(unidentified_attr_1_df)\n",
    "unidentified_attr_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing age from values to be 0\n",
    "unidentified_df['Age From'] = unidentified_df['Age From'].fillna(0)\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unidentified_agefrom_test_df = unidentified_df.loc[unidentified_df['Age From']==0]\n",
    "unidentified_agefrom_test_df\n",
    "# len(unidentified_agefrom_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for Age To\n",
    "unidentified_attr_2_df = unidentified_df.loc[unidentified_df['Age To'].isnull()]\n",
    "# len(unidentified_attr_2_df)\n",
    "unidentified_attr_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing age to values to be 120\n",
    "unidentified_df['Age To'] = unidentified_df['Age To'].fillna(120)\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unidentified_ageto_test_df = unidentified_df.loc[unidentified_df['Age To']==120]\n",
    "unidentified_ageto_test_df\n",
    "# len(unidentified_ageto_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for sex\n",
    "unidentified_attr_3_df = unidentified_df.loc[unidentified_df['Sex'].isnull()]\n",
    "# len(unidentified_attr_3_df)\n",
    "unidentified_attr_3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing sex values to be 'Unknown'\n",
    "unidentified_df['Sex'] = unidentified_df['Sex'].fillna('Unknown')\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unidentified_sex_test_df = unidentified_df.loc[unidentified_df['Sex']=='Unknown']\n",
    "unidentified_sex_test_df\n",
    "# len(unidentified_sex_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for race / ethnicity\n",
    "unidentified_attr_4_df = unidentified_df.loc[unidentified_df['Race / Ethnicity'].isnull()]\n",
    "# len(unidentified_attr_4_df)\n",
    "unidentified_attr_4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign missing race / ethnicity values to be 'Uncertain'\n",
    "unidentified_df['Race / Ethnicity'] = unidentified_df['Race / Ethnicity'].fillna('Uncertain')\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unidentified_race_test_df = unidentified_df.loc[unidentified_df['Race / Ethnicity']=='Uncertain']\n",
    "unidentified_race_test_df\n",
    "# len(unidentified_race_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Prep data for state-level GeoJSON with data from all 3 databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a: Add in State FIPS column to each database dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of states and state FIPS code\n",
    "state_dict = dict(zip(state_centroids_df.NAME, state_centroids_df.STATEFP))\n",
    "# state_dict\n",
    "# state_dict['Alaska']\n",
    "len(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1/3: add state FIPS codes to missing persons dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "missing_df['State_FIPS'] = missing_df['State'].map(state_dict)\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in new dataframe field\n",
    "missing_df['State_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If any nulls, check to see what is producing null values [NOTE: fixed by making changes to csv fields, as noted where csvs are imported]\n",
    "mis_test_df = missing_df.loc[missing_df['State_FIPS'].isnull()]\n",
    "mis_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing df\n",
    "missing_df.head()\n",
    "# len(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2/3: add state FIPS codes to unclaimed persons dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df.head()\n",
    "# len(unclaimed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "unclaimed_df['State_FIPS'] = unclaimed_df['State'].map(state_dict)\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in new dataframe field\n",
    "unclaimed_df['State_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If any nulls, check to see what is producing null values [NOTE: cannot be addressed, as these cases do not have a state or county assigned]\n",
    "unc_test_df = unclaimed_df.loc[unclaimed_df['State_FIPS'].isnull()]\n",
    "# len(unc_test_df)\n",
    "unc_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN FIPS codes (for cases with no city, county or state) to 99 (none option in state_centroids_v2.csv)\n",
    "unclaimed_df['State_FIPS'] = unclaimed_df['State_FIPS'].fillna(99)\n",
    "unclaimed_df['State_FIPS'] = unclaimed_df['State_FIPS'].astype(int)\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unc_test_df2 = unclaimed_df.loc[unclaimed_df['State_FIPS']==99]\n",
    "unc_test_df2\n",
    "# len(unc_test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check full dataframe\n",
    "len(unclaimed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3/3: add state FIPS codes to unidentified persons dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "unidentified_df['State_FIPS'] = unidentified_df['State'].map(state_dict)\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in new dataframe field\n",
    "unidentified_df['State_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If any nulls, check to see what is producing null values [NOTE: fixed by making changes to csv fields, as noted where csvs are imported]\n",
    "uni_test_df = unidentified_df.loc[unidentified_df['State_FIPS'].isnull()]\n",
    "uni_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Prep data for county-level JSONs for all 3 databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in State name and County_Key columns to county centroid v2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of state FIPS codes and state names\n",
    "state_FIPS_dict = dict(zip(state_centroids_v2_df.STATEFP, state_centroids_v2_df.NAME))\n",
    "# state_FIPS_dict\n",
    "# state_FIPS_dict['Alaska']\n",
    "len(state_FIPS_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check county centroids v2 df\n",
    "county_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "county_centroids_v2_df['STATE_NAME'] = county_centroids_v2_df['STATEFP'].map(state_FIPS_dict)\n",
    "# check dataframe\n",
    "county_centroids_v2_df.head()\n",
    "# Check unique values in new dataframe field\n",
    "# county_centroids_v2_df['STATE_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort county centroids by state FIPS\n",
    "county_centroids_v2_df = county_centroids_v2_df.sort_values(by=['STATEFP'])\n",
    "county_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with compound field key\n",
    "county_centroids_v2_df['County_Key'] = county_centroids_v2_df['STATEFP'].astype(str) + \"_\" + county_centroids_v2_df['NAME']\n",
    "county_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values and length\n",
    "county_key_v2_list = county_centroids_v2_df['County_Key'].unique()\n",
    "len(county_key_v2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of counties and county FIPS code (GEOID field)\n",
    "county_v2_dict = dict(zip(county_centroids_v2_df.County_Key, county_centroids_v2_df.GEOID))\n",
    "len(county_v2_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in County_key column to county centroids dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort county centroids by state FIPS\n",
    "county_centroids_df = county_centroids_df.sort_values(by=['STATEFP'])\n",
    "county_centroids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with compound field key\n",
    "county_centroids_df['County_Key'] = county_centroids_df['STATEFP'].astype(str) + \"_\" + county_centroids_df['NAME']\n",
    "county_centroids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values and length\n",
    "county_key_list = county_centroids_df['County_Key'].unique()\n",
    "len(county_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of counties and county FIPS code (GEOID field)\n",
    "county_dict = dict(zip(county_centroids_df.County_Key, county_centroids_df.GEOID))\n",
    "len(county_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in County FIPS column to missing dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To identify null values, add in County FIPS column to missing dataframe using county_centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing df\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with compound field key\n",
    "missing_df['State_County'] = missing_df['State_FIPS'].astype(str) + \"_\" + missing_df['County']\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the State_County name field as a key in the county_dict, to pull the correct County FIPS code for each row\n",
    "missing_df['County_FIPS'] = missing_df['State_County'].map(county_dict)\n",
    "# Check unique values in new dataframe field\n",
    "missing_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values [NOTE: all ok - no city or county assigned]\n",
    "missing_county_null_df = missing_df.loc[missing_df['County_FIPS'].isnull()]\n",
    "# missing_county_null_df.shape\n",
    "missing_county_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As needed, export nulls to address [NOTE: all that can have been addressed]\n",
    "# missing_county_null_df.to_csv('missing_county_nulls.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing_df\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace null state values with 'None' and null county values with 'None', then re-write county_FIPS column using county_centroids_v2_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'State'\n",
    "mis_state_test_df = missing_df.loc[missing_df['State'].isnull()]\n",
    "# len(mis_state_test_df)\n",
    "mis_state_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'City' and County'\n",
    "mis_county_test_df = missing_df.loc[missing_df['County'].isnull()]\n",
    "# len(mis_county_test_df)\n",
    "mis_county_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN County name (for cases with no city or county) to 'None'\n",
    "missing_df['County'] = missing_df['County'].fillna('None')\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "mis_county_test_2_df = missing_df.loc[missing_df['County']=='None']\n",
    "mis_county_test_2_df\n",
    "# len(mis_county_test_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Add column with compound field key\n",
    "missing_df['State_County'] = missing_df['State_FIPS'].astype(str) + \"_\" + missing_df['County']\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "mis_county_test_3_df = missing_df.loc[missing_df['County']=='None']\n",
    "mis_county_test_3_df\n",
    "# len(mis_county_test_3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add County FIPS column to dataframe, using the State_County name field as a key in the county_v2_dict, to pull the correct County FIPS code for each row\n",
    "missing_df['County_FIPS'] = missing_df['State_County'].map(county_v2_dict)\n",
    "# Check unique values in new dataframe field\n",
    "missing_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values to make sure none are left [Note - all gone!]\n",
    "missing_county_null_v2_df = missing_df.loc[missing_df['County_FIPS'].isnull()]\n",
    "# missing_county_null_v2_df.shape\n",
    "missing_county_null_v2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "mis_county_test_4_df = missing_df.loc[missing_df['County']=='None']\n",
    "mis_county_test_4_df\n",
    "# len(mis_county_test_4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in County FIPS column to unclaimed dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To identify null values, add in County FIPS column to unclaimed dataframe using county_centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unclaimed df\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with compound field key\n",
    "unclaimed_df['State_County'] = unclaimed_df['State_FIPS'].astype(str) + \"_\" + unclaimed_df['County']\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "unclaimed_df['County_FIPS'] = unclaimed_df['State_County'].map(county_dict)\n",
    "# Check unique values in new dataframe field\n",
    "unclaimed_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "unclaimed_county_null_df = unclaimed_df.loc[unclaimed_df['County_FIPS'].isnull()]\n",
    "# unclaimed_county_null_df.shape\n",
    "unclaimed_county_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As needed, export nulls to address [NOTE: all have been addressed. 1241 cases have no county]\n",
    "# unclaimed_county_null_df.to_csv('unclaimed_county_nulls.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unclaimed_df\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace null state values with 'None' and null county values with 'None', then re-write county_FIPS column using county_centroids_v2_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'State'\n",
    "unc_state_test_df = unclaimed_df.loc[unclaimed_df['State'].isnull()]\n",
    "# len(unc_state_test_df)\n",
    "unc_state_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN State name (for cases with no city or county or state) to 'None'\n",
    "unclaimed_df['State'] = unclaimed_df['State'].fillna('None')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unc_state_test_2_df = unclaimed_df.loc[unclaimed_df['State']=='None']\n",
    "unc_state_test_2_df\n",
    "# len(unc_state_test_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'City' and County'\n",
    "unc_county_test_df = unclaimed_df.loc[unclaimed_df['County'].isnull()]\n",
    "# len(unc_county_test_df)\n",
    "unc_county_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN County name (for cases with no city or county) to 'None'\n",
    "unclaimed_df['County'] = unclaimed_df['County'].fillna('None')\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unc_county_test_2_df = unclaimed_df.loc[unclaimed_df['County']=='None']\n",
    "unc_county_test_2_df\n",
    "# len(unc_county_test_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Add column with compound field key\n",
    "unclaimed_df['State_County'] = unclaimed_df['State_FIPS'].astype(str) + \"_\" + unclaimed_df['County']\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unc_county_test_3_df = unclaimed_df.loc[unclaimed_df['County']=='None']\n",
    "unc_county_test_3_df\n",
    "# len(unc_county_test_3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add County FIPS column to dataframe, using the State_County name field as a key in the county_v2_dict, to pull the correct County FIPS code for each row\n",
    "unclaimed_df['County_FIPS'] = unclaimed_df['State_County'].map(county_v2_dict)\n",
    "# Check unique values in new dataframe field\n",
    "unclaimed_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values to make sure none are left [Note - all gone!]\n",
    "unclaimed_county_null_v2_df = unclaimed_df.loc[unclaimed_df['County_FIPS'].isnull()]\n",
    "# unclaimed_county_null_v2_df.shape\n",
    "unclaimed_county_null_v2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "unc_county_test_4_df = unclaimed_df.loc[unclaimed_df['County']=='None']\n",
    "unc_county_test_4_df\n",
    "# len(unc_county_test_4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in County FIPS column to unidentified dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To identify null values, add in County FIPS column to unidentified dataframe using county_centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unidentified df\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with compound field key\n",
    "unidentified_df['State_County'] = unidentified_df['State_FIPS'].astype(str) + \"_\" + unidentified_df['County']\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to dataframe, using the state name field as a key in the state_dict, to pull the correct FIPS code for each row\n",
    "unidentified_df['County_FIPS'] = unidentified_df['State_County'].map(county_dict)\n",
    "# Check unique values in new dataframe field\n",
    "unidentified_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "unidentified_county_null_df = unidentified_df.loc[unidentified_df['County_FIPS'].isnull()]\n",
    "# unidentified_county_null_df.shape\n",
    "# len(unidentified_county_null_df)\n",
    "unidentified_county_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As needed, export nulls to address [NOTE - all have been addressed - 28 remain with no city or county]\n",
    "# unidentified_county_null_df.to_csv('unidentified_county_nulls.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unclaimed_df\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace null state values with 'None' and null county values with 'None', then re-write county_FIPS column using county_centroids_v2_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'State'\n",
    "uni_state_test_df = unidentified_df.loc[unidentified_df['State'].isnull()]\n",
    "# len(uni_state_test_df)\n",
    "uni_state_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if any rows with null value for 'City' and County'\n",
    "uni_county_test_df = unidentified_df.loc[unidentified_df['County'].isnull()]\n",
    "# len(uni_county_test_df)\n",
    "uni_county_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change NaN County name (for cases with no city or county) to 'None'\n",
    "unidentified_df['County'] = unidentified_df['County'].fillna('None')\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "uni_county_test_2_df = unidentified_df.loc[unidentified_df['County']=='None']\n",
    "uni_county_test_2_df\n",
    "# len(uni_county_test_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Add column with compound field key\n",
    "unidentified_df['State_County'] = unidentified_df['State_FIPS'].astype(str) + \"_\" + unidentified_df['County']\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "uni_county_test_3_df = unidentified_df.loc[unidentified_df['County']=='None']\n",
    "uni_county_test_3_df\n",
    "# len(uni_county_test_3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add County FIPS column to dataframe, using the State_County name field as a key in the county_v2_dict, to pull the correct County FIPS code for each row\n",
    "unidentified_df['County_FIPS'] = unidentified_df['State_County'].map(county_v2_dict)\n",
    "# Check unique values in new dataframe field\n",
    "unidentified_df['County_FIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values to make sure none are left [Note - all gone!]\n",
    "unidentified_county_null_v2_df = unidentified_df.loc[unidentified_df['County_FIPS'].isnull()]\n",
    "# unidentified_county_null_v2_df.shape\n",
    "unidentified_county_null_v2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double check re-assigned values\n",
    "uni_county_test_4_df = unidentified_df.loc[unidentified_df['County']=='None']\n",
    "uni_county_test_4_df\n",
    "# len(uni_county_test_4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Prep data for city-level JSONs for all 3 databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up city dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that aren't needed\n",
    "city_df = city_df.drop(columns=['FEATURE_CL','PRIMARY_LA', 'PRIM_LONG_', 'SOURCE_LAT', 'SOURCE_LON', 'SOURCE_L_1', 'SOURCE_L_2', 'ELEV_IN_M', 'ELEV_IN_FT', 'MAP_NAME', 'DATE_CREAT', 'DATE_EDITE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename coordinate columns\n",
    "city_df.rename(columns={'PRIM_LAT_D': 'Lat_dd', 'PRIM_LON_1': 'Lon_dd'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of states and state FIPS code\n",
    "state_dict = dict(zip(state_centroids_df.NAME, state_centroids_df.STATEFP))\n",
    "# state_dict\n",
    "# state_dict['Alaska']\n",
    "len(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframes\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct State-level GeoJSON with correct structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal format:\n",
    "{\n",
    "\"type\": \"Feature\",\n",
    "    \"name\": \"Wisconsin\",\n",
    "    \"properties\": {\n",
    "        \"missing\": [ ],\n",
    "        \"unclaimed\": [ ],\n",
    "        \"unidentified\": [ ],\n",
    "        \"filtered\": [ ]\n",
    "    }\n",
    "    \"geometry\": {\n",
    "          \"type\": \"Point\",\n",
    "          \"coordinates\": [\n",
    "            -117.79750667,\n",
    "            36.03755926\n",
    "          ]\n",
    "}\n",
    "* each array will be a list of dictionaries. Each dictionary = one case. Keys = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get headers\n",
    "missing_header = list(missing_df.columns.values)\n",
    "print(\"missing header:\", missing_header)\n",
    "unclaimed_header = list(unclaimed_df.columns.values)\n",
    "print(\"unclaimed header:\", unclaimed_header)\n",
    "unidentified_header = list(unidentified_df.columns.values)\n",
    "print(\"unidentified header:\", unidentified_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types\n",
    "type(unclaimed_df['State_FIPS'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check centroids\n",
    "state_centroids_v2_df.head()\n",
    "len(state_centroids_v2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each database by state FIPS\n",
    "# sort state centroids by state FIPS\n",
    "state_centroids_v2_df = state_centroids_v2_df.sort_values(by=['STATEFP'])\n",
    "state_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each database by state FIPS\n",
    "# sort missing by state FIPS\n",
    "missing_df = missing_df.sort_values(by=['State_FIPS'])\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unclaimed by state FIPS\n",
    "unclaimed_df = unclaimed_df.sort_values(by=['State_FIPS'])\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unidentified by state FIPS\n",
    "unidentified_df = unidentified_df.sort_values(by=['State_FIPS'])\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create state array\n",
    "state_array = []\n",
    "## for each state in state_centroids...\n",
    "i = 0\n",
    "while i < len(state_centroids_v2_df):\n",
    "    state_dict = {}\n",
    "    state_dict[\"type\"] = \"Feature\"\n",
    "    state_dict[\"name\"] = state_centroids_v2_df[\"NAME\"][i]\n",
    "    state_dict[\"name_abbr\"] = state_centroids_v2_df[\"STUSPS\"][i]\n",
    "    state_dict[\"state_FIPS\"] = str(state_centroids_v2_df[\"STATEFP\"][i])\n",
    "    state_dict[\"properties\"] = {}\n",
    "    missing_array = []\n",
    "    j = 0\n",
    "    while j < len(missing_df):\n",
    "        # check if state_fips matches\n",
    "        if missing_df['State_FIPS'][j] == state_centroids_v2_df[\"STATEFP\"][i]:\n",
    "            missing_dict = {}\n",
    "            for item in missing_header:\n",
    "                missing_dict[item] = str(missing_df[item][j])\n",
    "            # append dictionary to missing array\n",
    "            missing_array.append(missing_dict)\n",
    "        # increment j\n",
    "        j += 1\n",
    "    state_dict[\"properties\"]['missing'] = missing_array     \n",
    "    \n",
    "    unclaimed_array = []\n",
    "    k = 0\n",
    "    while k < len(unclaimed_df):\n",
    "        # check if state_fips matches\n",
    "        if unclaimed_df['State_FIPS'][k] == state_centroids_v2_df[\"STATEFP\"][i]:\n",
    "            unclaimed_dict = {}\n",
    "            for item in unclaimed_header:\n",
    "                unclaimed_dict[item] = str(unclaimed_df[item][k])\n",
    "            # append dictionary to unclaimed array\n",
    "            unclaimed_array.append(unclaimed_dict)\n",
    "        # increment k\n",
    "        k += 1\n",
    "    state_dict[\"properties\"]['unclaimed'] = unclaimed_array\n",
    "    \n",
    "    unidentified_array = []\n",
    "    l = 0\n",
    "    while l < len(unidentified_df):\n",
    "        # check if state_fips matches\n",
    "        if unidentified_df['State_FIPS'][l] == state_centroids_v2_df[\"STATEFP\"][i]:\n",
    "            unidentified_dict = {}\n",
    "            for item in unidentified_header:\n",
    "                unidentified_dict[item] = str(unidentified_df[item][l])\n",
    "            # append dictionary to unclaimed array\n",
    "            unidentified_array.append(unidentified_dict)\n",
    "        # increment l\n",
    "        l += 1\n",
    "    state_dict[\"properties\"]['unidentified'] = unidentified_array\n",
    "    \n",
    "    state_dict[\"properties\"]['filtered'] = []\n",
    "    ## set geometry\n",
    "    state_dict[\"geometry\"] = {}\n",
    "    state_dict[\"geometry\"][\"type\"] = \"Point\"\n",
    "    state_dict[\"geometry\"][\"coordinates\"] = [state_centroids_v2_df['Lon_dd'][i], state_centroids_v2_df['Lat_dd'][i]]\n",
    "    ## append state dictionary to array\n",
    "    state_array.append(state_dict)\n",
    "    # increment interator\n",
    "    i += 1\n",
    "# state_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check item in array\n",
    "len(state_array)\n",
    "# state_array[0]['properties']['unclaimed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FeatureCollection\n",
    "state_feature_collection = {}\n",
    "state_feature_collection[\"type\"] = \"FeatureCollection\"\n",
    "state_feature_collection[\"features\"] = state_array\n",
    "# state_feature_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FeatureCollection to JSON format\n",
    "state_geojson = geojson.dumps(state_feature_collection)\n",
    "# check type to make sure conversion was sucessful\n",
    "print(type(state_geojson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON-formatted FeatureCollection as JSON file\n",
    "# Save as new json file\n",
    "with open('JSON/state_geojson.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(state_geojson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct COUNTY-LEVEL GeoJSON with correct structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal format:\n",
    "{\n",
    "\"type\": \"Feature\",\n",
    "    \"name\": \"Dane\",\n",
    "    \"state\": \"Wisconsin\",\n",
    "    \"state_FIPS\": ,\n",
    "    \"county_FIPS\": ,\n",
    "    \"properties\": {\n",
    "        \"missing\": [ ],\n",
    "        \"unclaimed\": [ ],\n",
    "        \"unidentified\": [ ],\n",
    "        \"filtered\": [ ]\n",
    "    }\n",
    "    \"geometry\": {\n",
    "          \"type\": \"Point\",\n",
    "          \"coordinates\": [\n",
    "            -117.79750667,\n",
    "            36.03755926\n",
    "          ]\n",
    "}\n",
    "* each array will be a list of dictionaries. Each dictionary = one case. Keys = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get headers\n",
    "missing_header = list(missing_df.columns.values)\n",
    "print(\"missing header:\", missing_header)\n",
    "unclaimed_header = list(unclaimed_df.columns.values)\n",
    "print(\"unclaimed header:\", unclaimed_header)\n",
    "unidentified_header = list(unidentified_df.columns.values)\n",
    "print(\"unidentified header:\", unidentified_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types\n",
    "type(unclaimed_df['State_FIPS'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check centroids\n",
    "county_centroids_v2_df.head()\n",
    "len(county_centroids_v2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each database by county FIPS\n",
    "# sort county centroids by county FIPS\n",
    "county_centroids_v2_df = county_centroids_v2_df.sort_values(by=['GEOID'])\n",
    "county_centroids_v2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each database by county FIPS\n",
    "# sort missing by county FIPS\n",
    "missing_df = missing_df.sort_values(by=['County_FIPS'])\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unclaimed by county FIPS\n",
    "unclaimed_df = unclaimed_df.sort_values(by=['County_FIPS'])\n",
    "unclaimed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort unidentified by county FIPS\n",
    "unidentified_df = unidentified_df.sort_values(by=['County_FIPS'])\n",
    "unidentified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create county array \n",
    "county_array = []\n",
    "## for each county in county_centroids_v2...\n",
    "i = 0\n",
    "while i < len(county_centroids_v2_df):\n",
    "    county_dict = {}\n",
    "    county_dict[\"type\"] = \"Feature\"\n",
    "    county_dict[\"name\"] = str(county_centroids_v2_df[\"NAME\"][i])\n",
    "    county_dict[\"county_FIPS\"] = str(county_centroids_v2_df[\"GEOID\"][i])\n",
    "    county_dict[\"state_name\"] = str(county_centroids_v2_df[\"STATE_NAME\"][i])\n",
    "    county_dict[\"state_FIPS\"] = str(county_centroids_v2_df[\"STATEFP\"][i])\n",
    "    county_dict[\"properties\"] = {}\n",
    "    missing_array = []\n",
    "    j = 0\n",
    "    while j < len(missing_df):\n",
    "        # check if state_fips matches\n",
    "        if missing_df['County_FIPS'][j] == county_centroids_v2_df[\"GEOID\"][i]:\n",
    "            missing_dict = {}\n",
    "            for item in missing_header:\n",
    "                missing_dict[item] = str(missing_df[item][j])\n",
    "            # append dictionary to missing array\n",
    "            missing_array.append(missing_dict)\n",
    "        # increment j\n",
    "        j += 1\n",
    "    county_dict[\"properties\"]['missing'] = missing_array     \n",
    "    \n",
    "    unclaimed_array = []\n",
    "    k = 0\n",
    "    while k < len(unclaimed_df):\n",
    "        # check if state_fips matches\n",
    "        if unclaimed_df['County_FIPS'][k] == county_centroids_v2_df[\"GEOID\"][i]:\n",
    "            unclaimed_dict = {}\n",
    "            for item in unclaimed_header:\n",
    "                unclaimed_dict[item] = str(unclaimed_df[item][k])\n",
    "            # append dictionary to unclaimed array\n",
    "            unclaimed_array.append(unclaimed_dict)\n",
    "        # increment k\n",
    "        k += 1\n",
    "    county_dict[\"properties\"]['unclaimed'] = unclaimed_array\n",
    "    \n",
    "    unidentified_array = []\n",
    "    l = 0\n",
    "    while l < len(unidentified_df):\n",
    "        # check if state_fips matches\n",
    "        if unidentified_df['County_FIPS'][l] == county_centroids_v2_df[\"GEOID\"][i]:\n",
    "            unidentified_dict = {}\n",
    "            for item in unidentified_header:\n",
    "                unidentified_dict[item] = str(unidentified_df[item][l])\n",
    "            # append dictionary to unclaimed array\n",
    "            unidentified_array.append(unidentified_dict)\n",
    "        # increment l\n",
    "        l += 1\n",
    "    county_dict[\"properties\"]['unidentified'] = unidentified_array\n",
    "    \n",
    "    county_dict[\"properties\"]['filtered'] = []\n",
    "    ## set geometry\n",
    "    county_dict[\"geometry\"] = {}\n",
    "    county_dict[\"geometry\"][\"type\"] = \"Point\"\n",
    "    county_dict[\"geometry\"][\"coordinates\"] = [county_centroids_v2_df['Lon_dd'][i], county_centroids_v2_df['Lat_dd'][i]]\n",
    "    ## append county dictionary to array\n",
    "    county_array.append(county_dict)\n",
    "    # test statement\n",
    "    print(\"added county\", str(i+1), \"of 3283\")\n",
    "    # increment interator\n",
    "    i += 1\n",
    "# county_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check item in array\n",
    "len(county_array)\n",
    "# county_array[55]['properties']['unclaimed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FeatureCollection\n",
    "county_feature_collection = {}\n",
    "county_feature_collection[\"type\"] = \"FeatureCollection\"\n",
    "county_feature_collection[\"features\"] = county_array\n",
    "# county_feature_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FeatureCollection to JSON format\n",
    "county_geojson = geojson.dumps(county_feature_collection)\n",
    "# check type to make sure conversion was sucessful\n",
    "print(type(county_geojson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON-formatted FeatureCollection as JSON file\n",
    "# Save as new json file\n",
    "with open('JSON/county_geojson.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(county_geojson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 make State and County polygon GeoJSONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load state shapefile\n",
    "state_gdf = gpd.read_file('Shapefiles/state_polygons.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x168b9556e48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to geoJSON\n",
    "state_gdf.to_file(\"JSON/state_polygons.json\", driver=\"GeoJSON\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load county shapefile\n",
    "county_gdf = gpd.read_file('Shapefiles/county_polygons.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x168bf46b948>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAByCAYAAABKpoqAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAW8ElEQVR4nO3df3Ac533f8ff32d27w+E3CBACf0j8AZoiaTmWhUqqZceSIiuWMx1ZSdMof0SeJqnTNuo4qdOpXM00nnraxk6cTNOkaeTYHadt7HbGtaOmthXZrS1LciORtEWKpUTxpwiSAkCC+EHgcHe7z7d/7JKGSIAASQCHA76vmZu7e+4HPrdYfLH37LPPiqpijDGm/rhaBzDGGHN9rIAbY0ydsgJujDF1ygq4McbUKSvgxhhTp6yAG2NMnQrneoKIbAf+27SmLcC/BNqAfwAMZe3/QlW/seAJjTHGzEiuZRy4iATAKeAu4O8DF1T19xYpmzHGmKu41i6UnwKOqOqJxQhjjDFm/ubsQrnMo8CXp91/XEQeA3YDn1DV85e/QEQ+BnwMoLGx8Y5bb731erMaY8yqtGfPnrOq2nV5+7y7UEQkB5wGdqnqgIh0A2cBBT4N9KjqL1/tPfr6+nT37t3XHN4YY1YzEdmjqn2Xt19LF8pDwF5VHQBQ1QFVTVTVA58H7lyYqMYYY+bjWrpQfpFp3Sci0qOqZ7K7jwCvLmSwhXZyeJKh8TLHz02w58R5tq1t5B3dLagqd23uIAwDvPc4ZyMrjTH1YV4FXESKwAeBX5vW/FkReTdpF8rxyx5bFgbGpnjya/s5fm6Sw4MXZn1ea0OECMSJsrmzyE2tDbQUQtqKOYYnKuzsaeHBXd3csqZxCdMbY8zVzauAq+oksOaytl9alEQ3qJp4/t2332BwfIrdx88zNF4mVqUhF1CNPQok/u39/qOl6qXb+0+Nsf/UGFs6G2nIBQAcGhgnTjz/6L7epfwoxhhzVdc6CmXZiwLHr75/M8+9McT33zjLRCXmsnpNWzGit6uJ0VKFUtXP+D6nR0pMxT9+7L7taxcztjHGXLMVV8CPDl3guUNDnB4p8W8fuY2JSsxvP32A0VKVTWsa6WjMoYD3yuB4mdFSPK/3VezEF8aY5WXFFHBVZWi8zDMHBvjMt14D4AdHz1GIAt65rpXYe54/fG7O97lzcweogghx4pkoxxRzIVFgOzeNMctL3RfwwbEpyrFnY0eRtS0F/uEHtvBz71lPOfbkQ4dX5a/2neaZAwMzvr69GLGtu5mJcoxXpVRJWNMUceJcibdGpyhVEwDu6e1cyo9ljDFzqvsCXsgFTFYS9r55nts3tiEitDfm+O2v7+f0WJmRySptxYiXj19xkCgAu9a1UE0UJ3B2vMJEJeat0YC2Yo7etY0UooDhicoSfypjjJlb3RfwlkJESyFiEz8e4vdH//sN/uLlfnb0NFOIAuLE864NrYxPxVRjf2l0iariRBiZrDA6Waa7tYEkUfKRY++bI5fer7Uhoilf94vKGLPC1HVVmizHNOQCRORS2943z/O+3k6OnZ3g6VfO0JgLmKgkbOxooBAGxC4t+mcnyjREAYcHL/Dr9/fyZ98/RuKVe3tb2NnTxB0bW9hzcox8GJCPHCOlCt85OMDdW9bQaMXcGLMMXNN0sjdqKeZCqcSeSpyQDx0jpSpvjZb5ja/sJQwCjp2boL0hoqetgdcHxnloVze/9UAvLx4exEvIfb2tFItFClFAEAR4rziX/nM4NVLi+OAY3z9ynr5b2nm1fxgR4bH3bqa9Mb+on8kYs7rNNhfKiivglyuVq1QST2Mu4MxYha/u7ecLzx/j/lvX8t5NbQxPlHnsni00FnLzfs/Dg+N8+YVDlCsx50qeX39wJ+9c17qIn8IYs5otxGRWy1ac+CuOrryoIR/RWsxzdqLK13/Yz77+Ef7gZ3fwbz7yTt4YmuCOLV0U89E1/bzetc08/uAucvk8t6wp8h+ePcC+kyMs5T9DY4xZ0Vvg5XKZZ187y/B4ieELZXb0tPDAO9chIniF8AbHdk9VY577fyf5Ly8cBRE6Ozr4/V949wKlN8aY1Gxb4Ctyb9zw+CSHBiZQgS3tER/csZbh0Qt0r2m9NNvgQnz1KEQhD9x2C4Vcjra8kIQNC/CuxhgzP/OdjfA4MA4kQKyqfSLSQXqy402ksxH+vZnOyLMUkiTdcXl4cIyJiue2dS3c3fv2k1f0dLUvys92zvGTO9YvynsbY+rL6GSV5kJ4afDDYruWLfD7VPXstPtPAN9R1d8RkSey+/98QdNNkySekVKFC5Ml2hvzjJeVtmKOQhRQiT1h4Lht45q538gYYxZJQy5gqlKlWMihqpTjhABQceTChd/leCNdKA8D92a3vwR8l0Us4HFcpbUQ0VbMEzihZdrU3A02T4kxZhnIhY5cmI5oExEKUUg18QSyOFvk8618Cvy1iOzJTlIM0H3xjDzZ9YzzrYrIx0Rkt4jsHhoauu6g+XyeMAwIluirST2ZbQSOMab2osAtWt2a7xb4Pap6WkTWAs+KyGvz/QGq+hTwFKSjUK4jY10bGisxNnKeL710mjBX4PXBC9zcXiRwQuBgfCpGVQkCRz50VGKlks1DXkk8nU05vFdE0hWh6pXISVq0xaPeUY4T3rWxjY3tRfpuaachFyKSTRVgp4gzZsWa7xl5TmfXgyLyNdITGA9cPC+miPQAg4uYs249/8ZZvnXgDIEoU2MT5APHmdEpnCjegzgQhMR7vEIlToi90lQIGSsljJUqRIGjkiQ05nOkL4LApdPdOhwV7/nmvjOcGJ7k3Rvb+Olb29m1vgMVYWv39R1gpKq8eOQcN7UW2NrVtMBLxRizEOYs4CLSCDhVHc9uPwj8K+Bp4KPA72TXf7mYQevVB7Z38cyrp6l4x8hUhbaGgNClX6kSgXOTFdoKEZFzuEAoRgEqiqrgtcr5yYT1bXnyYQQoOq3gu6xfrRA4otCxa10LocALR0f51sHzgKe3qxEBOvMJH3rXRjo72uaV++s/PMVX9/Zzy5pG/vUjty3a8jHGXL/5bIF3A1/LJowKgb9Q1W+JyMvAfxeRXwHeBH5+8WLWL+ccKoL3SnM+xKuSoFSrabdJSyFiouK5UK7SWgjJhQEOJRGhrSHH+FSVyYoSOk8QCJVqTFM+vHjOCdCEqioiDhUoVZVS7BGFXAAfvLWDPSdG2Xu6xKaeKd7XcWVGVeUHR84xVqrgVRmeiPn2wbcQhIGRCwyOTbG2pbDky84Yc3VzFnBVPQr8xAzt54CfWoxQK0n/+UnKsUJWcCMXUvEJI6WY7uYcLhBKKOvbG0iShHMTVYo5RyEKODtZIa4mNEZC5CIEyEcB1UTTvdqqBM6hXnEoXhw+SQiCAFVoK+aQsMALx04gwCv9I9y1tYsoDN6W8anvHuLlN0fRWAnC9HRzeV+mYfwCOzuhq9km6zJmOVqRR2IuJ/v6R/GajhQpVROcSxgYm0IVpqoJN7c30FaMUFUEIXJCJVEODYxQzEe0NUS4MERc2v09OhXT0RihHoLA4T048TgXIurRIEgLuhM6WxrobmlIDypQODQwwfnJKmtbAgZGS3zmmwdRlNJUQuhAQ0CEJIn5pw+8g52bemq9+IwxV2EFfJHt7Gnmm/vPMFlJiEKhIQrIBY6WQsh4OeHYcIme1gJDoyU2dBRpLER879AQO3taODQwTntDDucEB4gTOooRE6UqzQ05Eu8RAIVEE0TTrXKvCT5xHB26wJ8+dxhNFMHTkQ946ehZ9vWP0H++ROxB1SPq8bEiztGSDyjkIsaqNV5wxpg5WQFfZBcqCUo6wD9yQrmakAsdbcX0TEL9IyWqsWesHGdHbnnu3dbJyGSF923tIIljzo2X6WzOETgIVCnmA5R0RKYooIIqoB4PBEEIqkxOVTlejYEYJwGnx2NOvdIPAkJAgOIB7xw+ibmtM8+H+7byju7mt50kwxizPNkg4UX2vt4uQgetBUdTwdFcCNOdmVk3x+B4mVzo6GrO45wjHzicE9Y054iCdGRKV1MOwRHgUHEELgQRRAVxAWnZdijgNetvzwq8ekUV4mqV2CeoV0hAfUwljonjKnlN2NrZxEfv3cn2m1qseBtTJ6yAL4FPPLidggP1kKiSC4WqV350coStXU2ETugs5piqJERBepBOkJXgKApJvCdwkKhHVYl9DF5B0oIduIAg7eYmDAKcU2LNukd8QlL1VOP0td57vFd84tFEiQJHVxHu3bmOjibbWWlMPbECvgRu29DOXdu6ib2SJEroHJPlhHVtDUSBpFu8Tih7T6IQBcJUokxW0n7tiheqSbpF7RBCl54HVAS8T0jwePVI4FCFJNH0v4UoXoQwDIhyIQgkPsFJupUehEE6LLGxkXsum73RGLP8WQFfIj/7no10tzaQCwNKVU9LQ0hrQ0Q19vzwzfMcGZrgpWPnOT9ZZaycUI49U3GCB8IAck7SoYKkXSIAAgShwyHg0u4SAXCCU8FJgACiiiaKQwgkPYCIwKGiBLmAIIpIEl+rRWOMuU5WwJdIQy7gH9+7lQ0dBRrzIeNTMXtODHN6dIr1bQXOjE7xgW2dlKsJokoUQGshohwnaAIeEHG4tCLj1aPpTRKvSHqEPeo96RGbjvSYTUciDnEKmiBBmBZ3rwQS8BMb1vB3b19PYDM6GlN3bBTKEtrQ0cgnP7STsxem+E8vnqC5EBF7T5woqmn3SWdTnoaco5oolSQB4K3xKTZ1NBKrxwk4J2h2OH2ApOO8BUQFj0d8Wuh9okggBB4qPt2xGWh6dGg+Cnn8/l622U5LY+qWFfAllosCetqKPH7fNgbGp3AC//OVM3Q05Tg5XKK7JU8lVnKho5p4KrGnqymPqicKBMShqunBOgpe0n5xyAq7F3wcE+ZyEKbdLaoJGnvCKCKuxvSuX8Ov3beV9kbbaWlMPbMCXgMiQmsxorUYAfCbH2wG4OTwJGdGpkCUrV1NdDTm+MLzx3jx8Nn0aE5N+8FREE1QcThxqCaAkKiiWTcJmk52paQH6IT5HIKQywuPvfcWK97GrABWwJeRjR1FNnYU39b2q+/fQv/5SZ49MMCjd27k4JmxdKy3BKCKqCcXOG7ubKaaJIxOlBieqPJgbyt37dhELgx48fAgE1MxB94a4+xYmZFSzLoafUZjzMIRvTikYQn09fXp7t27r+u1qrqq+2pPnZ9kfXuRo0MX+N1nXsMn6c7KTZ1FfuFvbWLL2nQrvlyNGR4Zo6m5meZC9Lb3OHrmHJ/59lF6O4v8s4d21eBTGGOuh4jsUdW+y9vnHHogIhtF5P+IyEEROSAiH8/aPyUip0TkR9nlw4sRfFoOAOI4xvvVN+RtfXu6Zb6lq4n7tq8l8Up3VOGTP3PbpeINkI9Cero6rijeAGtamogETg6XGC/ZZCfG1Lv5dKHEwCdUda+INAN7ROTZ7LE/UNXfW7x4VwrDNPLFLfLVuGX+kdvXMzBaorN4ZZG+mtbGPA/uuon/tf8t+kcm2dFwfWfrMcYsD/OZD/wMcPHkxeMichBYv9jB5nKxaE8v3qulmOfCgH/ywPZrfp33nvu3d/G95/axrev2RUhmjFlK13T0hohsAm4H/iZrelxE9onIF0WkfZbXLMhZ6eeZD4Bq1boHZuKcI3TwuY//zKVvMsaY+jXvAi4iTcBXgd9Q1THgT4CtwLtJt9A/N9PrVPUpVe1T1b6urqWZbyOKfty1cHEnrfdLt7N2OSsU7NRoxqwU8yrgIhKRFu//qqr/A0BVB1Q1UVUPfJ70TPXLzsV+8oHxEtU4oX/4ApVqXOtYxhhzw+YzCkWALwAHVfX3p7VPP9/WI8CrCx9vYYgIPa1FojCgp62RI2cnOT1SqnUsY8wSU1WSbIqKlWA+W+D3AL8E3H/ZkMHPish+EdkH3Af85mIGXSiBE9qKEc8dWtz+eGPM8pNOw7xyBjrMZxTK88BMn/gbCx9nafS0NvDonTfXOkZd8N7z7595gR2dbfT1bqSjva3WkYwxGRuKYK7KOcfHH3p/rWMYs2CW8ujzxWaTQBtjVpmV04ViBdwYs6qspLNPWQE3xqwak+UqURTUOsaCsT5wY8yqUcxf2/xBy51tgRtjTJ2yAm6MMXXKCrgxxtQpK+DGGFOnrIAbY0ydsgJujDF1ygq4McbUqRsq4CLyIRF5XUQOi8gTCxXKGGPM3K67gItIAPwx8BCwE/hFEdm5UMGMMcZc3Y1sgd8JHFbVo6paAb4CPLwwsYwxxszlRgr4euDktPv9zHC2+qU8qbExxqwmN1LAZ5qT8YqJdmtxUmNjjFkNbqSA9wMbp93fAJy+sTjGGGPm60YK+MvANhHZLCI54FHg6YWJZYwxZi7XPZ2sqsYi8jjwDBAAX1TVAwuWzBhjzFXd0HzgqvoN6vjkxsYYU8/sSExjjKlTVsCNMaZOWQE3xpg6tSIKuOoVw8+NMWbFWxEFXGSmY4qMMWZlWxEFvFqNieO41jGMMWZJ3dAwwuUiDANEBFW1rXFjzKqxIrbALxZtK97GmNVkRRRwY4xZjayAG2NMnZKlHIInIkPAiSX7gdeuEzhb6xDzUC85oX6yWs6FVy9Z6yHnLap6xXzcS1rAlzsR2a2qfbXOMZd6yQn1k9VyLrx6yVovOWdiXSjGGFOnrIAbY0ydsgL+dk/VOsA81UtOqJ+slnPh1UvWesl5BesDN8aYOmVb4MYYU6esgBtjTJ1alQVcRH5eRA6IiBeRvmntm0SkJCI/yi7/cdpjd4jIfhE5LCJ/KEt03P5sWbPHPpnleV1Efnpa+4eytsMi8sRS5Lws16dE5NS05fjhuTLXUq2X19WIyPFsvfuRiOzO2jpE5FkReSO7bq9Rti+KyKCIvDqtbcZskvrDbBnvE5H31DhnXa2js1LVVXcBdgDbge8CfdPaNwGvzvKal4C/DQjwTeChGmfdCbwC5IHNwBHSk0sH2e0tQC57zs4lXr6fAn5rhvYZM9d4Xaj58poj33Gg87K2zwJPZLefAD5To2w/Cbxn+t/MbNmAD2d/NwLcDfxNjXPWzTp6tcuq3AJX1YOq+vp8ny8iPUCLqv5A09/ynwMfWbSA01wl68PAV1S1rKrHgMPAndnlsKoeVdUK8JXsucvBbJlraTkvr9k8DHwpu/0llmhdvJyqPgcMX9Y8W7aHgT/X1P8F2rK/q1rlnM1yXEdntSoL+Bw2i8gPReR7IvL+rG090D/tOf1ZWy2tB05Ou38x02ztS+3x7KvyF6d9xV8u2aZbjpmmU+CvRWSPiHwsa+tW1TMA2fXamqW70mzZluNyrpd1dFYrYj7wmYjIt4GbZnjoSVX9y1ledga4WVXPicgdwNdFZBfp177LLdj4y+vMOlummf4pL/hY0atlBv4E+HT2cz8NfA74ZRZ5OV6n5ZhpuntU9bSIrAWeFZHXah3oOi235VxP6+isVmwBV9UHruM1ZaCc3d4jIkeAd5D+F94w7akbgNMLkTP7WdeclTTTxmn3p2earX3BzDeziHwe+Kvs7tUy18pyzHSJqp7OrgdF5GukX+cHRKRHVc9k3RCDNQ35drNlW1bLWVUHLt6ug3V0VtaFMo2IdIlIkN3eAmwDjmZfBcdF5O5s9MljwGxbxkvlaeBREcmLyGbSrC8BLwPbRGSziOSAR7PnLpnL+jYfAS7u/Z8tcy3VfHnNRkQaRaT54m3gQdJl+TTw0expH6X26+J0s2V7GngsG41yNzB6saulFupsHZ1drfei1uJC+gvrJ93aHgCeydp/DjhAuhd6L/B3pr2mj/SXfAT4I7KjWGuVNXvsySzP60wbFUO6x/9Q9tiTNVi+/xnYD+wj/YPomStzjdeHmi6vq+Takq2Lr2Tr5ZNZ+xrgO8Ab2XVHjfJ9mbTbsZqto78yWzbSrok/zpbxfqaNqKpRzrpaR2e72KH0xhhTp6wLxRhj6pQVcGOMqVNWwI0xpk5ZATfGmDplBdwYY+qUFXBjjKlTVsCNMaZO/X8CNfXNUTfTOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "county_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to geoJSON\n",
    "county_gdf.to_file(\"JSON/county_polygons.json\", driver=\"GeoJSON\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
